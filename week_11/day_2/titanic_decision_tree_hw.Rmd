---
title: "Tuesday homework - titanic decision tree"
output: html_notebook
---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)
library(janitor)

titanic_set <- read_csv('data/titanic_decision_tree_data.csv') %>% 
  clean_names()

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```
Data dictionary from homework file:

* sex: Biological Sex, male or female
* age_status: adult or child (child defined as under 16)
* class : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)
* port_embarkation: C = Cherbourg, Q = Queenstown, S = Southampton
* sibsp : number of siblings / spouses aboard the Titanic
* parch: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them.
* survived_flag : did they survive, 0 = No, 1 = Yes    

# 1. Cleaning

```{r}
titanic_subset <- titanic_set %>% #1309
  filter(!is.na(survived)) %>% #891 rows
  mutate(age_status = case_when(
    age <= 16 ~ "child",
    age > 16 ~ "adult",
    .default = NA_character_), .after = age) %>%
  mutate(across(.cols = c(sex, survived, pclass, embarked, age_status),
                .fns = ~ factor(.x))) %>% 
  mutate(pclass = factor(pclass, levels = c("1", "2", "3")),
         survived = factor(survived, levels = c("1", "0"), labels = c("yes","no"))) %>% 
  select(-c(x1, passenger_id, name, ticket, fare, cabin)) %>% 
  drop_na() # 712 rows
```

Dropped 179 rows with NAs:

* 177 NAs in age and age status
* 2 diff NAs in embarked

```{r}
# check factor levels
levels(titanic_subset$survived) # survived = TRUE (1) is first
levels(titanic_subset$pclass)
```

```{r}
dim(titanic_subset)
```

712 observations
8 vars - 7 predictors (incl. both age + age_status) of outcome (survived)

# 2. Explore predictors

```{r, message = FALSE}
titanic_subset %>% 
  GGally::ggpairs(progress = F)
```

Promising predictor vars (with approximate strength of correlation): 

 * pclass - looks like proportion(survived) changes with class
 * sex - definite pattern in survived v not by gender
 * age_status - different changes in box size here - top row survived slightly more than not; bottom row survived less than not survived
 * embarked - looks like a pattern in survived v embarkation location - some proportions(survived) lower than others 

Notice also that age, parch, sib_sp are correlated - because age status child --> has siblings and parents (or not), maybe once age_status used the other variables may not contribute much

```{r}
alias(survived ~ ., titanic_subset)
```

No aliases in the numeric data

```{r}
skimr::skim(titanic_subset)
```

# 3. Test-train split

We have 712 observations - use 20% for test

```{r}
# set up test-train split
test_split <- 0.2
n_data <- nrow(titanic_subset)

test_index <- sample(1:n_data, size = n_data * test_split)

# split data
titanic_test <- slice(titanic_subset, test_index)
titanic_train <- slice(titanic_subset, -test_index)

# check proportion(survived) in whole, test and train
tabyl(titanic_test, survived)
tabyl(titanic_train, survived)
tabyl(titanic_subset, survived)
```

In whole df, 40% survived; in train df, 41% survived and in test df, 39% survived.

So the split is fairly balanced. Proceed as is.

```{r}
dim(titanic_train)
dim(titanic_test)
```

Check: 570 obs (80% of 712) in training dataset, 142 (20%) in test.

# 4. Make decision tree model

```{r}
titanic_fit <- rpart(survived ~ .,
                     data = titanic_train,
                     method = "class",
                     control = rpart.control(minsplit = 3))

tree <- rpart.plot(titanic_fit,
           yesno = 1, 
           fallen.leaves = TRUE, 
           faclen = 6, 
           digits = 4, 
           type = 4, 
           split.border.col = 8,
           box.palette = "GnRd")
```

# 5. Intrepret decision tree model

```{r}
titanic_fit
```

Note the probability decimals are prob(0, "no") not prob(1, "yes"), so prob(survived) = 1 - decimal

> Q: order of yesno flag important for tree but reverse order for what's needed for yardstick?

* In the full training dataset, prob(survival) = 100 - 59.3% = 40.7%
* The first predictor the data is split by is sex, whereby being female increased chance of survival: if female (35% of the 570 passengers in this training dataset), prob(survival) = 76% (100 - 24%); if male (74% of the passengers here), prob(survival) = 21.4% (100 - 78.6%)
* In females, the next predictor is passenger class:
  * females of class 1 or 2 (upper or middle) were more likely to survive: 22% of passengers, prob(survival) = 94%
  * for females in lower class (class 3; 14% of all passengers), prob(survival) was less at 44%, and the next split is by age:
    * lower class females aged less than 5 years, 1.75% of passengers are predicted as 99.8% likely to survive
    * lower class females aged 5.5 (incl.) to 32.5 (exclusive), 9.8% of passengers, are predicted as 41% likely to survive
    * lower class females aged 32.5 (incl.) to 38.5 (exclusive), 0.7% of passengers, are predicted as 100% likely to survive - **highest chance of survival for any demographic in this model**
    *  lower class females aged 38.5 years or above, 1.8% passengers, are predicted to have a 0% chance of survival - **lowest chance of survival for any demographic in this model**
* In males, the next predictor is not class, but age:
 * males aged less than 13 years (5.4% passengers) have a predicted survival probability of 61% - but if they have fewer than 2 siblings (3.3% passengers), their prob(survival) is increased to 95%, while if they have 3 or more siblings, their prob(survival) drops to 8%.
 * Men of 13 years or older, of any other characteristics, make up 58% of passengers and are predicted not to survive (prob(survival) = 18%)

These data suggest that the following passengers were prioritised in the lifeboats:

* women of upper and middle class
* age bands may indicate that lower class mothers (32.5-38.5 years old) with young children (5.5 years or less) were prioritised
* children of either sex, with girls prioritised over boys where families had 4 or more children (boys with 3 or more siblings were much less likely to survive)

# 6. Predict test set & analyse tree performance

```{r}
titanic_test_pred <- titanic_test %>% 
  modelr::add_predictions(titanic_fit, type = "class")

head(titanic_test_pred)
```

```{r}
titanic_test_pred %>% 
  yardstick::conf_mat(truth = survived, estimate = pred)
```

```{r}
TP <- 35
FN <- 22
TN <- 81
FP <- 4

accuracy <- (TP + TN) / (TP + TN + FP + FN)
  
TPR_sens <- TP / (TP + FN)
  
TNR_spec <- TN / (TN + FP)

accuracy
TPR_sens
TNR_spec
```

Accuracy of predicting survival or not is 81.7% (using data in which 40% passengers survived)

Sensitivity is 61.4% (rate at which model predicts true for all true cases)

Specificity is 95.2% (rate at which model predicts false for all false cases)

So this model is pretty sensitive to non-survival, but is not managing to predict survived for all survived passengers (some predicted as not survived).

Maybe this makes sense for a model that is imbalanced towards non-survival.

# Extension

Create a random forest model

```{r}
library(ranger)

titanic_classifier <- ranger(survived ~ .,
                             titanic_train,
                             importance = "impurity",
                             num.trees = 500,
                             min.node.size = 3)

titanic_classifier
```

```{r}
importance(titanic_classifier)
```

The most important predictor to split by is sex, then passenger class, then age. This matches the individual decision tree model already made.

```{r}
titanic_test_rf_pred <- titanic_test %>% 
  mutate(pred = predict(titanic_classifier, data = titanic_test)$predictions)

head(titanic_test_rf_pred, 20)
```


```{r}
caret::confusionMatrix(titanic_test_rf_pred$pred, titanic_test_rf_pred$survived)
```

Compare to signle decision tree:

```{r}
caret::confusionMatrix(titanic_test_pred$pred, titanic_test_pred$survived)
```

Kappa is higher in the random forest model, as are accuracy, sensitivity and specificity too.

_Did not tune the hyperparamters, out of time._


```{r}
# make function for doing all the yardstick measures
# not working: .data indirection may not work for yardstick 
# https://dplyr.tidyverse.org/articles/programming.html#indirection
# - stopping here -

model_stats <- function(df, flag, pred) {
  
  conf_mat <- df %>% 
    yardstick::conf_mat(truth = .data[[flag]], estimate = .data[[pred]])
  
  # accuracy <- df %>% 
  #   yardstick::accuracy(truth = {flag}, estimate = {pred})
  # 
  # sensitivity_TPR <- df %>% 
  #   yardstick::sensitivity(truth = {flag}, estimate = {pred})
  # 
  # specificity_TNR <- df %>% 
  #   yardstick::specificity(truth = {flag}, estimate = {pred})
  # 
  # stats_tbl <- tibble(c("accuracy" = accuracy,
  #          "specificity or TPR" = specificity_TPR,
  #          "sensitivity or TNR" = sensitivity_TNR))
  
  print(conf_mat)
  #print(stats_tbl)
}
```

```{r}
model_stats(df = titanic_test_pred, flag = survived, pred = pred)
```


